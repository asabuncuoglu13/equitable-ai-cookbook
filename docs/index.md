# Equitable AI Cookbook

Equitable AI involves creating and using artificial intelligence systems in a fair and just manner, ensuring they do not reinforce existing biases or discriminate against certain groups. It focuses on fairness, transparency, accountability, inclusivity, and ethical considerations to prevent unfair outcomes and promote equal opportunities for all individuals and communities.

I think it is fair to say that equitable AI is a broder term that covers responsible, trustworthy and inclusive AI development. In this sense, we can say that it is an established research area, and the existing research can guide us to take some confident steps to achieve trustworthiness in the era of *large foundational models*. 

There have already been many good papers and books on the responsible and trustworthy use and development of AI. My plan is not to write another. In this cookbook, I gather some best practices from the literature and sectoral use cases, and present them in recipes to implement efficiently in real-life scenarios. This repository contains an extensive list of techniques and experiments as an initial effort to achieve this goal in the "digital economy" domain. In the digital economy domain, we selected three use cases:

1.  Internal use of LLMs in financial services such as credit scoring and financial insight generation,
2.  Improving biometric facial verification using synthetic data generated by foundational models (e.g. diffusion models)
3.  Utilising LLMs in fraud detection in KYC (know-your-customer) systems.

This cookbook is an effort to bring the "best practices" together to achieve equitable AI, particularly focusin on the use cases from public services and digital economy. "Best practices" can widely refer to a set of techniques, methodologies, processes, or guidelines that are accepted as superior or most effective in a particular field or context. These practices are typically based on accumulated knowledge, experience, and empirical evidence of what works well and produces desirable outcomes. We can define "best practices" to optimize efficiency, productivity, quality, safety, or other desired outcomes.

When the desired outcome is achieving equal access/outcomes/participation/benefits and trustworthiness, defining the "best practices" becomes challenging as these are complex sociotechnical terms. For example, NIST defines "trustworthiness" with seven sub-components, and each subcomponent requires a careful evaluation based on specific use cases. 

In a complex product development ecosystem, it is hard to achive "trustworthiness," as all sub-modules of a product is expected to achieve trustworthiness. Therefore, the desirable way to achieve trustworthiness is following a proactive "by design" approach in the product design. In this cookbook, we explored the ways to achieve this kind of proactive approach, however implementing them in a product lifecycle is still up to tangible and intangible capabilities of development teams.

## Contents

Although implementing "best practices" in equitable AI domain requires a cross disciplinary effort, we focused on the sociotechnical and technical techniques, particularly fairness, security and privacy. We do not go into details on governance, auditing techniques, comprehensive assurance.

```{tableofcontents}
```
# Equitable AI Cookbook

Equitable AI involves creating and using artificial intelligence systems in a fair and just manner, ensuring they do not reinforce existing biases or discriminate against certain groups. It focuses on fairness, transparency, accountability, inclusivity, and ethical considerations to prevent unfair outcomes and promote equal opportunities for all individuals and communities.

```{note}
This cookbook is a work-in-progress. You can contribute to the development by opening new issues and pull requests on Github.
```

In this cookbook, *equitable AI* refers to a broad term to cover responsible, trustworthy and inclusive AI development. These terms also requires establishing other characteristics such as security, privacy, and fairness. For example, NIST AI RMF[^airmf] defines *trustworthiness* with seven sub-components: Safe, secure and resilient, explainable and interpretable, privacy-enhanced, fair with harmful bias managed, valid and reliable, and accountable and transparent. Each subcomponent requires a careful evaluation based on specific use cases. In this sense, *equitable AI* is a combination of various established research areas.

![NIST Trustworthy AI Characteristics](./media/nist-trustworthy.png)

This cookbook is an effort to bring *best practices* from the literature and share some hands-on practical experiments to take some confident steps for achieving trustworthiness in the era of *large foundational models*. "Best practices" can widely refer to a set of techniques, methodologies, processes, or guidelines that are accepted as superior or most effective in a particular field or context. When the desired outcome is achieving equal access/outcomes/participation/benefits and *trustworthiness*, defining best practices becomes challenging, as these are complex sociotechnical terms.

This repository contains an extensive list of techniques and experiments as an initial effort to achieve this goal in the "digital economy" domain. In the digital economy domain, we selected three use cases:

::::{grid}
:gutter: 2

:::{grid-item-card}
**Fair Use of LLMs in Finance**

Developing more fair and equitable applications (e.g. credit scoring, financial news sentiment analysis, market prediction) powered by AI.

[➡️ See the content](./usecases/finance/introduction.md)
:::

:::{grid-item-card}
**A Fairness Benchmark for Facial Biometrics**

Improving biometric facial verification using synthetic data generated by foundational models (e.g. diffusion models)

[➡️ See the content](./usecases/biometrics/introduction.md)

:::
::::

Jupyter notebooks of this cookbook demonstrate existing bias evaluation and mitigation approaches in action. In a complex product development ecosystem, it is hard to achive "trustworthiness," as all sub-modules of a product is expected to achieve trustworthiness. Therefore, the desirable way to achieve trustworthiness is following a proactive "by design" approach in the product design. In this cookbook, we explored the ways to achieve this kind of proactive approach, however implementing them in a product lifecycle is still up to technical capacity of development teams.

## Related Materials

This cookbook assumes, you already have some understanding on AI and maybe developed an AI-enabled product, but limited experience in assessing, managing and monitoring safety, equity and fairness of these products. Below, we listed some wonderful open-source books that can help you adopt best-practices of ML development in a broader context:

- [The Turing Way:](https://book.the-turing-way.org/index.html) A guide for reproducible project design, development and management.
- [Techwork's Best Practice Guide:](https://techworkshub.github.io/best-practice-guide/index.html) Five essential questions: (1) Should I use AI/ML? (2) How do I define my AI/ML project (3) How do I collect data? (4) How do I train my AI/ML application? (5) How do I deploy my AI/ML application?

## Contents

Although implementing "best practices" in equitable AI domain requires a cross disciplinary effort, we focused on the sociotechnical and technical techniques, particularly fairness, security and privacy. We do not go into details on governance, auditing techniques, comprehensive assurance.

```{tableofcontents}
```

[^airmf]: https://www.nist.gov/itl/ai-risk-management-framework
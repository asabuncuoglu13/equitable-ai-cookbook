# Toolkits and Checklists for AI Safety

Researchers and practitioners develops checklists and toolkits that can audit the model outputs in a systematic way.

**Some popular guardrail libraries:**
- https://github.com/NVIDIA/NeMo-Guardrails

However, this approach also brings the challenge of "toolkitification" in which the term coined by Hollanek {cite}`hollanek_2024`. His article critically examines the "toolkitification" trend in AI ethics, where toolkits are increasingly used to translate ethical theories into practice. The author argues that most AI ethics toolkits embody a reductionist approach to ethics, often dissociating it from politics and reducing ethical considerations to a checklist for engineers. This limits their capacity to drive meaningful change in AI development. The paper also explores alternative toolkits informed by feminist theory, posthumanism, and critical design, which emphasize the inseparability of ethics and politics. These alternative toolkits aim to foster power-sensitive dialogues among stakeholders and challenge dominant design paradigms.

## Analysis of Toolkitisation in AI Safety, Privacy, and Trustworthiness

Toolkitisation in AI safety, privacy, and trustworthiness faces similar limitations. By focusing on compliance with predefined standards, these toolkits often simplify complex ethical issues into technical fixes, potentially neglecting broader socio-political and environmental implications. Alternative approaches that integrate diverse ethical frameworks, such as feminist and decolonial theories, could provide a more holistic understanding of these components, ensuring that toolkits do not merely enforce existing power structures but contribute to more equitable and inclusive AI practices.
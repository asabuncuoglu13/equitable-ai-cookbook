# Equitable AI Cookbook

Equitable AI involves creating and using artificial intelligence systems in a fair and just manner, ensuring they do not reinforce existing biases or discriminate against certain groups. It focuses on fairness, transparency, accountability, inclusivity, and ethical considerations to prevent unfair outcomes and promote equal opportunities for all individuals and communities. This cookbook is an effort to bring the "best practices" together to achieve equitable AI, particularly focusin on the use cases from public services and digital economy.

"Best practices" can widely refer to a set of techniques, methodologies, processes, or guidelines that are accepted as superior or most effective in a particular field or context. These practices are typically based on accumulated knowledge, experience, and empirical evidence of what works well and produces desirable outcomes. We can define "best practices" to optimize efficiency, productivity, quality, safety, or other desired outcomes.

When the desired outcome is achieving equal access/outcomes/participation/benefits and trustworthiness, defining the "best practices" becomes challenging as these are complex sociotechnical terms. For example, NIST defines "trustworthiness" with seven sub-components, and each subcomponent requires a careful evaluation based on specific use cases.

In the recent survey directed by CDEI, public opinion on AI related to trustworthy integration to public and private sector applications has been explored [^1]. They listed six main outcomes:

1.  **Focus on equitable AI/Data:** How society can benefit from the use of data or AI equally.

2.  **Secure data flow:** Building confidence that organisations will be responsible for their actions.

3.  **Image of AI:** With the increasing AI experience, the public becomes more pessimistic about the outcomes.

4.  **Apprehensions about change:** Although increasing productivity in the day-to-day jobs are expected, there is also a concern mostly about job displacement.

5.  **The preference is situation-dependent:** Utilising AI in social good projects such as cancer detection and financial support is highly favourable. However, clear risk management strategies can help public to support the rest of the use cases.

6.  **Low digital familiarity:** If the end users have lower digital literacy, they tend to be more pessimistic about the use of AI/data.

In the same report, they presented the following chart illustrating the opportunities for data use:

![CDEI's chart on AI opportunities in public services](https://assets.publishing.service.gov.uk/media/656f2ea50f12ef07a53e0268/Slide2.SVG)

Health (21%), the cost of living (18%), and the economy (8%) appeared as
the most promising data-driven opportunities in the public eye. The rest
of the <10% opportunities are also digital economy-related.

95% of survey participants from the public claim that they had heard of
AI, with a significant portion (66%) stating they can provide at least a
partial definition of it. Despite increasing familiarity and utilization
of AI, persistent concerns are associated with the technology, with
feelings of *scary*, *worry*, and *unsure* being frequently expressed
[^1].

The adoption of LLMs is quite prevalent, with around a third (34%) of
the UK populace utilizing chatbots in their personal lives on a monthly
basis, and a quarter (24%) incorporating them into their work routines.
Consequently, self-reported awareness and comprehension of AI among the
UK public have shown an uptick since last year across various
demographic segments, encompassing older individuals, those from lower
socio-economic backgrounds, and individuals with lower levels of digital
proficiency [^1].

In Microsoft's New Future of Work Report 2023 report, we see that the
integration of LLMs is not only expected into internal applications, but
many companies will also include them as client and worker-facing
applications [^2]. It includes an array of tasks including LLMs for
information work, critical thinking, human-AI collaboration, complex and
creative tasks, domain-specific applications, team collaboration and
communication, knowledge management and organisational change, future
work and society.

From an academic perspective, we can observe that equitable AI is an
established research area, and the existing research can guide us to
take confident steps to achieve trustworthiness in the era of large
foundational models. However, we should take the next steps in an
interdisciplinary and transparent fashion. This repository contains an
extensive list of techniques and experiments as an initial effort to
achieve this goal in the "digital economy" domain. In the digital
economy domain, we selected three use cases:

1.  Internal use of LLMs in financial services such as credit scoring
    and financial insight generation,
2.  Improving biometric facial verification using synthetic data
    generated by foundational models (e.g. diffusion models)
3.  Utilising LLMs in fraud detection in KYC (know-your-customer)
    systems.

## Contents

```{tableofcontents}
```


[^1]: Centre for Data Ethics and Innovation and Department for Science,
Innovation & Technology, 'Public attitudes to data and AI: Tracker
survey (Wave 3) (Section 6: Attitudes towards AI)'. Accessed: Mar. 18.
<https://www.gov.uk/government/publications/public-attitudes-to-data-and-ai-tracker-survey-wave-3/public-attitudes-to-data-and-ai-tracker-survey-wave-3>

[^2]: J. Butler *et al.*, 'Microsoft New Future of Work Report 2023',
Microsoft, MSR-TR-2023-34, Dec. 2023.
<https://www.microsoft.com/en-us/research/publication/microsoft-new-future-of-work-report-2023/>